---
title: "0183411 蔡宇"
author: "yu cai"
date: "2021/5/23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

10.a
```{r}
library(ISLR)
summary(Weekly)
pairs(Weekly)
cor(Weekly[,-9])
```
There is a high correlation between year and volume

b.
```{r}
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Weekly,family=binomial)
summary(glm.fit)
```
The p value of lag2 was less than 0.05, which was statistically significant.

c.
```{r}
glm.probs=predict(glm.fit,type="response")
glm.pred=rep("Down",length(glm.probs))
glm.pred[glm.probs>0.5]="Up"
table(glm.pred,Direction)
```
The prediction accuracy was (54 + 557) / (54 + 48 + 430 + 557) = 55.7%.
When the prediction of weak increases, the correct rate is 557 / (557 + 48) = 92.1%,
When the prediction of weak decreases, the correct rate is 54 / (430 + 54) = 11.2%.

d.
```{r}
train=(Year<2009)
Weekly.0910=Weekly[!train,]
glm.fit=glm(Direction~Lag2,data=Weekly,family=binomial,subset=train)
glm.probs=predict(glm.fit,Weekly.0910,type="response")
glm.pred=rep("Down",length(glm.probs))
glm.pred[glm.probs>0.5]="Up"
Direction.0910=Direction[!train]
table(glm.pred,Direction.0910)
mean(glm.pred==Direction.0910)
```
The overall prediction accuracy is 0.625.

e.
```{r}
library(MASS)
lda.fit=lda(Direction~Lag2,data=Weekly,subset=train)
lda.pred=predict(lda.fit,Weekly.0910)
table(lda.pred$class,Direction.0910)
mean(lda.pred$class == Direction.0910)
```
The overall prediction accuracy is 0.625.

f.
```{r}
qda.fit=qda(Direction~Lag2,data=Weekly,subset=train)
qda.class=predict(qda.fit,Weekly.0910)$class
table(qda.class,Direction.0910)
mean(qda.class==Direction.0910)
```
The overall prediction accuracy is 0.587.

g.
```{r}
library(class)
train.X=as.matrix(Lag2[train])
test.X=as.matrix(Lag2[!train])
train.Direction=Direction[train]
set.seed(1)
knn.pred=knn(train.X,test.X,train.Direction,k=1)
table(knn.pred,Direction.0910)
mean(knn.pred==Direction.0910)
```
The overall prediction accuracy is 0.5.

h.
According to the data, logistic regression and LDA have the highest accuracy and the best results.

i.
```{r}
glm.fit=glm(Direction~Lag2:Lag1,data=Weekly,family=binomial,subset=train)
glm.probs=predict(glm.fit,Weekly.0910,type="response")
glm.pred=rep("Down",length(glm.probs))
glm.pred[glm.probs>0.5]="Up"
Direction.0910=Direction[!train]
table(glm.pred,Direction.0910)
mean(glm.pred==Direction.0910)
```

```{r}
lda.fit=lda(Direction~Lag2:Lag1,data=Weekly,subset=train)
lda.pred=predict(lda.fit,Weekly.0910)
table(lda.pred$class,Direction.0910)
mean(lda.pred$class==Direction.0910)
```

```{r}
qda.fit=qda(Direction~Lag2+sqrt(abs(Lag2)),data=Weekly,subset=train)
qda.class=predict(qda.fit,Weekly.0910)$class
table(qda.class,Direction.0910)
mean(qda.class==Direction.0910)
```

```{r}
knn.pred=knn(train.X,test.X,train.Direction,k=10)
table(knn.pred,Direction.0910)
mean(knn.pred==Direction.0910)
```

```{r}
knn.pred=knn(train.X,test.X,train.Direction,k=100)
table(knn.pred,Direction.0910)
mean(knn.pred==Direction.0910)
```
Compared with the above results, the correct rate of logistic regression is the highest.

11.a.
```{r}
library(ISLR)
summary(Auto)
attach(Auto)
mpg01=rep(0,length(mpg))
mpg01[mpg>median(mpg)]=1
Auto=data.frame(Auto,mpg01)
```

b.
```{r}
cor(Auto[,-9])
pairs(Auto)
```
Cyclinders, weight, displacement and horsepower have strong influence on mpg01 prediction.

c.
```{r}
train=(year%%2==0)
test=!train
Auto.train=Auto[train,]
Auto.test=Auto[test,]
mpg01.test=mpg01[test]
```

d.
```{r}
library(MASS)
lda.fit=lda(mpg01~cylinders+weight+displacement+horsepower,data=Auto,subset=train)
lda.pred=predict(lda.fit,Auto.test)
mean(lda.pred$class!=mpg01.test)
```
The test error is 0.126.

e.
```{r}
qda.fit=qda(mpg01~cylinders+weight+displacement+horsepower,data=Auto,subset=train)
qda.pred=predict(qda.fit,Auto.test)
mean(qda.pred$class!=mpg01.test)
```
The test error is 0.132.

f.
```{r}
glm.fit=glm(mpg01~cylinders+weight+displacement+horsepower,data=Auto,family=binomial,subset=train)
glm.probs=predict(glm.fit,Auto.test,type="response")
glm.pred=rep(0,length(glm.probs))
glm.pred[glm.probs>0.5]=1
mean(glm.pred!=mpg01.test)
```
The test error is 0.121.

g.
```{r}
library(class)
train.X=cbind(cylinders,weight,displacement,horsepower)[train,]
test.X=cbind(cylinders,weight,displacement,horsepower)[test,]
train.mpg01=mpg01[train]
set.seed(1)
knn.pred=knn(train.X,test.X,train.mpg01,k=1)
mean(knn.pred != mpg01.test)
knn.pred=knn(train.X,test.X,train.mpg01,k=5)
mean(knn.pred != mpg01.test)
knn.pred=knn(train.X,test.X,train.mpg01,k=10)
mean(knn.pred != mpg01.test)
```
When k = 10, the test error is 0.154.
When k = 5, the test error is the smallest and the effect is the best.
